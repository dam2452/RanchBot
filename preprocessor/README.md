# Video Preprocessing Pipeline

Aplikacja Docker do przetwarzania wideo z akceleracjÄ… GPU (NVIDIA): transkodowanie, transkrypcja (Whisper/ElevenLabs), detekcja scen, eksport klatek, wykrywanie postaci, generowanie embeddingÃ³w i indeksowanie w Elasticsearch.

---

## âš ï¸ Wymagania sprzÄ™towe

> **UWAGA: Ta aplikacja zostaÅ‚a zaprojektowana, zoptymalizowana i przetestowana WYÅÄ„CZNIE na RTX 3090 (24GB VRAM) + 64GB RAM.**
>
> Wszystkie domyÅ›lne ustawienia (batch size=28, VRAM usage, cache) sÄ… skalibrowane pod tÄ™ konkretnÄ… konfiguracjÄ™.
> Uruchomienie na innym sprzÄ™cie wymaga manualnego dostosowania parametrÃ³w i moÅ¼e nie dziaÅ‚aÄ‡ poprawnie.

| Komponent | **Konfiguracja testowa (jedyna wspierana)** |
|-----------|-------------------------------------------|
| **GPU** | **RTX 3090 24GB** |
| **VRAM** | **24GB** |
| **RAM** | **64GB** |
| **Dysk** | **150GB+ SSD NVMe** |

**Aplikacja dziaÅ‚a TYLKO na GPU NVIDIA. Brak fallbacku na CPU.**

### Specyfikacja RTX 3090 + 64GB RAM

- **Batch size 28** dla embeddingÃ³w wykorzystuje ~10GB z 24GB VRAM
- **PeÅ‚ne cache modeli** (~25GB) trzymane w RAMie bez swapowania
- **Bez OOM** przy rÃ³wnoczesnym dziaÅ‚aniu Ollamy i preprocessora
- **NVENC hardware encoding** dla 1080p h264

### ZuÅ¼ycie VRAM (RTX 3090 - 24GB)

| Operacja                       | VRAM | Konfiguracja |
|--------------------------------|------|--------------|
| Transcode (NVENC)              | ~2GB | h264_nvenc preset slow |
| Whisper large-v3-turbo         | ~3GB | CTranslate2 float16 |
| TransNetV2                     | ~2GB | PyTorch CUDA |
| **Embeddings (batch_size=28)** | **~10GB** | **DomyÅ›lne dla RTX 3090** |
| InsightFace (buffalo_l)        | ~1GB | ArcFace face recognition |
| LLM scraping (Qwen 8-bit)      | ~8GB | Ollama 8-bit quantization |
| **Peak Å‚Ä…cznie**               | **~12GB** | **PoÅ‚owa VRAM 3090 = margines bezpieczeÅ„stwa** |

---

## Quick Start

### PeÅ‚ny pipeline (od zera)

```bash
cd preprocessor
mkdir -p input_data/videos output_data
cp /twoje/wideo/*.mp4 input_data/videos/

docker-compose build

./run-preprocessor.sh run-all /input_data/videos \
  --scrape-urls https://ranczo.fandom.com/wiki/Seria_I \
  --character-urls https://ranczo.fandom.com/wiki/Lista_postaci \
  --series-name ranczo

docker logs ranchbot-preprocessing-app -f
```

### Z gotowÄ… transkrypcjÄ… i transkodowaniem

```bash
./run-preprocessor.sh detect-scenes /input_data/transcoded_videos

./run-preprocessor.sh export-frames /input_data/transcoded_videos \
  --episodes-info-json /input_data/episodes.json \
  --scene-timestamps-dir /app/output_data/scene_timestamps \
  --name ranczo

./run-preprocessor.sh image-hashing \
  --frames-dir /app/output_data/frames_480p \
  --episodes-info-json /input_data/episodes.json \
  --name ranczo

./run-preprocessor.sh generate-embeddings \
  --transcription-jsons /app/output_data/transcriptions \
  --frames-dir /app/output_data/frames_480p

./run-preprocessor.sh generate-elastic-documents \
  --transcription-jsons /app/output_data/transcriptions \
  --embeddings-dir /app/output_data/embeddings \
  --scene-timestamps-dir /app/output_data/scene_timestamps \
  --name ranczo

./run-preprocessor.sh index --name ranczo \
  --elastic-documents-dir /app/output_data/elastic_documents
```

---

## Architektura pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         run-all Pipeline (11 krokÃ³w)                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                                            â”‚
â”‚  [0a/9] scrape episodes   â†’  [1/9] transcode  â†’  [2/9] transcribe  â†’  [3/9] detect scenes                â”‚
â”‚         (Qwen + crawl4ai)      (NVENC)             (Whisper)            (TransNetV2)                      â”‚
â”‚                                                                                                            â”‚
â”‚  [0b/9] scrape characters â†’  [0c/9] download references                                                   â”‚
â”‚         (Qwen + crawl4ai)       (DuckDuckGo + InsightFace)                                                â”‚
â”‚                                                                                                            â”‚
â”‚  [4/9] export frames  â†’  [5/9] frame processing (5 sub-krokÃ³w):                                           â”‚
â”‚        (480p JPG)              [5a] image hashing (perceptual hash)                                       â”‚
â”‚                                [5b] video embeddings (Qwen2-VL per-frame)                                 â”‚
â”‚                                [5c] character detection (InsightFace)                                     â”‚
â”‚                                [5d] object detection (D-FINE-X)                                           â”‚
â”‚                                [5e] object visualization (annotated frames)                               â”‚
â”‚                                                                                                            â”‚
â”‚  [6/9] text embeddings  â†’  [7/9] generate elastic docs  â†’  [8/9] index                                   â”‚
â”‚        (Qwen2-VL)              (JSON merging)                  (Elasticsearch)                            â”‚
â”‚                                                                                                            â”‚
â”‚  CaÅ‚kowicie SEKWENCYJNE przetwarzanie (pipeline + pliki w kaÅ¼dej fazie)                                   â”‚
â”‚  Optymalizacja dla jednego GPU bez strat wydajnoÅ›ci                                                       â”‚
â”‚                                                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Czas przetwarzania (RTX 3090 + 64GB RAM)

| Faza                           | Czas (45 min odcinek) |
|--------------------------------|----------------------|
| Transcode (NVENC)              | ~2 min |
| Transcribe (Whisper)           | ~5 min |
| Scene detection (TransNetV2)   | ~3 min |
| Export frames (480p)           | ~2 min |
| Frame processing (5/9)         | ~12-15 min |
| - Image hashing (5a)           | ~1 min |
| - Video embeddings (5b)        | ~5-7 min |
| - Character detection (5c)     | ~2 min |
| - Object detection (5d)        | ~2-3 min |
| - Object visualization (5e)    | ~1-2 min |
| Text embeddings (6/9)          | ~3-5 min |
| Generate elastic docs          | ~1 min |
| Index (Elasticsearch)          | ~2 min |
| **ÅÄ…cznie**                    | **~28-32 min** |

**Throughput:** ~2-3 odcinki (45 min kaÅ¼dy) na godzinÄ™ przetwarzania.

**Jednorazowo (na caÅ‚Ä… seriÄ™):**
- Scrape episodes: ~1-2 min (wszystkie sezony)
- Scrape characters: ~1-2 min (wszystkie postacie)
- Download references: ~5-10 min (zaleÅ¼nie od liczby postaci)

---

## Struktura projektu

```
preprocessor/
â”œâ”€â”€ cli/                     # Interfejs CLI (modularny)
â”‚   â”œâ”€â”€ commands/           # Komendy CLI (16 moduÅ‚Ã³w)
â”‚   â”œâ”€â”€ options/            # WspÃ³lne opcje CLI
â”‚   â”œâ”€â”€ pipeline/           # Orchestrator pipeline
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ config/                  # Konfiguracja aplikacji
â”œâ”€â”€ core/                    # BaseProcessor, StateManager
â”œâ”€â”€ video/                   # Przetwarzanie wideo
â”‚   â”œâ”€â”€ transcoder.py       # FFmpeg + NVENC
â”‚   â”œâ”€â”€ scene_detector.py   # TransNetV2
â”‚   â””â”€â”€ frame_exporter.py   # Eksport klatek (480p)
â”œâ”€â”€ transcription/           # Transkrypcja audio
â”‚   â”œâ”€â”€ engines/            # Whisper, ElevenLabs
â”‚   â”œâ”€â”€ generators/         # JSON, SRT, TXT
â”‚   â””â”€â”€ processors/         # Normalizacja audio
â”œâ”€â”€ scraping/                # Scrapowanie metadanych
â”‚   â”œâ”€â”€ episode_scraper.py  # crawl4ai + Ollama (odcinki)
â”‚   â”œâ”€â”€ character_scraper.py # crawl4ai + Ollama (postacie)
â”‚   â””â”€â”€ crawl4ai.py
â”œâ”€â”€ characters/              # Wykrywanie postaci
â”‚   â”œâ”€â”€ detector.py         # InsightFace face recognition
â”‚   â””â”€â”€ reference_downloader.py # DuckDuckGo image search
â”œâ”€â”€ hashing/                 # Perceptual hashing
â”‚   â””â”€â”€ image_hash_processor.py
â”œâ”€â”€ embeddings/              # Generowanie embeddingÃ³w
â”‚   â”œâ”€â”€ generator.py        # Qwen2-VL
â”‚   â”œâ”€â”€ episode_name_embedder.py # Embeddingi nazw odcinkÃ³w
â”‚   â””â”€â”€ strategies/         # Frame selection
â”œâ”€â”€ indexing/                # Elasticsearch
â”‚   â”œâ”€â”€ elastic_document_generator.py
â”‚   â””â”€â”€ indexer.py
â”œâ”€â”€ search/                  # elastic_manager
â”œâ”€â”€ providers/               # LLM (Ollama)
â”œâ”€â”€ input_data/              # [volume] Dane wejÅ›ciowe (read-only)
â”œâ”€â”€ output_data/             # [volume] Dane wygenerowane
â””â”€â”€ docker-compose.yml
```

### Wolumeny Docker

| Host | Container | Tryb |
|------|-----------|------|
| `input_data/` | `/input_data` | read-only |
| `output_data/` | `/app/output_data` | read-write |
| `ml_models` (named) | `/models` | persistent (~25GB) |

---

## Komendy CLI

Wszystkie komendy: `./run-preprocessor.sh <komenda> [args]` (z folderu `preprocessor`)

Pomoc: `./run-preprocessor.sh --help`

### run-all

PeÅ‚ny pipeline ze wszystkimi krokami (11 krokÃ³w: 0a-0c, 1-8).

```bash
# Z automatycznym scrapingiem metadanych (odcinki + postacie)
./run-preprocessor.sh run-all /input_data/videos \
  --scrape-urls https://ranczo.fandom.com/wiki/Seria_I \
  --character-urls https://ranczo.fandom.com/wiki/Lista_postaci \
  --series-name ranczo

# Z istniejÄ…cym episodes.json
./run-preprocessor.sh run-all /input_data/videos \
  --episodes-info-json /input_data/episodes.json \
  --series-name ranczo

# PominiÄ™cie wybranych krokÃ³w
./run-preprocessor.sh run-all /input_data/videos \
  --episodes-info-json /input_data/episodes.json \
  --series-name ranczo \
  --skip-transcode \
  --skip-frame-export \
  --skip-image-hashing \
  --skip-video-embeddings \
  --skip-character-detection \
  --skip-object-detection \
  --skip-object-visualization

# Premium modes (Gemini parser, ElevenLabs transcription, Google Images)
./run-preprocessor.sh run-all /input_data/videos \
  --scrape-urls https://ranczo.fandom.com/wiki/Seria_I \
  --character-urls https://ranczo.fandom.com/wiki/Lista_postaci \
  --series-name ranczo \
  --parser-mode premium \
  --transcription-mode premium \
  --search-mode premium
```

**DostÄ™pne flagi skip:**
- `--skip-transcode` - Krok 1: Transkodowanie
- `--skip-transcribe` - Krok 2: Transkrypcja
- `--skip-scenes` - Krok 3: Detekcja scen
- `--skip-frame-export` - Krok 4: Eksport klatek
- `--skip-image-hashing` - Krok 5a: Image hashing (sub-krok)
- `--skip-video-embeddings` - Krok 5b: Video embeddings (sub-krok)
- `--skip-character-detection` - Krok 5c: Character detection (sub-krok)
- `--skip-object-detection` - Krok 5d: Object detection (sub-krok)
- `--skip-object-visualization` - Krok 5e: Object visualization (sub-krok)
- `--skip-embeddings` - Krok 6: Text embeddings
- `--skip-elastic-documents` - Krok 7: Generowanie dokumentÃ³w Elasticsearch
- `--skip-index` - Krok 8: Indeksowanie

**Premium modes:**
- `--parser-mode premium` - Gemini 2.5 Flash zamiast Qwen (scraping)
- `--transcription-mode premium` - ElevenLabs API zamiast Whisper
- `--search-mode premium` - Google Images API zamiast DuckDuckGo

### scrape-episodes

Batch scraping metadanych odcinkÃ³w.

**Flow:** URLe â†’ crawl4ai (markdown) â†’ Qwen2.5-Coder-7B (128K context) â†’ JSON

```bash
./run-preprocessor.sh scrape-episodes \
  --urls https://ranczo.fandom.com/wiki/Seria_I \
  --urls https://ranczo.fandom.com/wiki/Seria_II \
  --output-file /input_data/episodes.json

# Z premium parser mode (Gemini 2.5 Flash)
./run-preprocessor.sh scrape-episodes \
  --urls https://ranczo.fandom.com/wiki/Seria_I \
  --output-file /input_data/episodes.json \
  --parser-mode premium
```

**Uwaga:** Scraping postaci (`--character-urls`) i pobieranie ich referencyjnych zdjÄ™Ä‡ dzieje siÄ™ automatycznie w ramach `run-all` pipeline. Brak osobnych komend CLI dla tych operacji.

### transcode

Transkodowanie wideo (Jellyfin FFmpeg 7 + NVENC).

```bash
./run-preprocessor.sh transcode /input_data/videos \
  --episodes-info-json /input_data/episodes.json \
  --resolution 1080p
```

### transcribe

Transkrypcja audio (Whisper large-v3-turbo).

```bash
./run-preprocessor.sh transcribe /input_data/videos \
  --episodes-info-json /input_data/episodes.json \
  --name ranczo \
  --model large-v3-turbo
```

### transcribe-elevenlabs

Transkrypcja przez ElevenLabs API (pÅ‚atne, speaker diarization).

```bash
export ELEVEN_API_KEY=your_key
./run-preprocessor.sh transcribe-elevenlabs /input_data/videos \
  --name ranczo \
  --episodes-info-json /input_data/episodes.json
```

### import-transcriptions

Import istniejÄ…cych transkrypcji.

```bash
./run-preprocessor.sh import-transcriptions \
  --source-dir /input_data/11labs_output \
  --name ranczo \
  --format-type 11labs_segmented
```

### detect-scenes

Detekcja scen (TransNetV2).

```bash
./run-preprocessor.sh detect-scenes /input_data/transcoded_videos \
  --threshold 0.5
```

### export-frames

Eksport klatek wideo (480p) na podstawie scene timestamps.

```bash
./run-preprocessor.sh export-frames /input_data/transcoded_videos \
  --episodes-info-json /input_data/episodes.json \
  --scene-timestamps-dir /app/output_data/scene_timestamps \
  --name ranczo \
  --frame-height 480
```

### image-hashing

Generowanie perceptual hashes dla wyeksportowanych klatek.

```bash
./run-preprocessor.sh image-hashing \
  --frames-dir /app/output_data/frames_480p \
  --episodes-info-json /input_data/episodes.json \
  --name ranczo \
  --batch-size 28
```

### generate-embeddings

Generowanie embeddingÃ³w tekstowych i wideo (gme-Qwen2-VL-2B).

**UWAGA:** Ta komenda generuje tylko **text embeddings** (domyÅ›lnie `--generate-text`).
Video embeddings sÄ… generowane w kroku 5b (frame processing) podczas `run-all`.

**Text embedding chunking:**

DomyÅ›lnie uÅ¼ywa **sentence-based chunking** z nastÄ™pujÄ…cymi parametrami:
- **8 zdaÅ„** na chunk (konfigurowalne)
- **3 zdania overlapa** miÄ™dzy chunkami (~37.5%)
- **Normalizacja interpunkcji**: `...` â†’ `.`, `!!!` â†’ `!`, `???` â†’ `?`
- **Minimalna dÅ‚ugoÅ›Ä‡**: 30 znakÃ³w (Å‚Ä…czy krÃ³tkie fragmenty)
- **Finalne chunki**: ~240-480 znakÃ³w kontekstu

```bash
# Text embeddings z sentence-based chunking (domyÅ›lnie)
./run-preprocessor.sh generate-embeddings \
  --transcription-jsons /app/output_data/transcriptions \
  --frames-dir /app/output_data/frames_480p \
  --batch-size 28

# Dostosowanie parametrÃ³w sentence chunking
./run-preprocessor.sh generate-embeddings \
  --transcription-jsons /app/output_data/transcriptions \
  --frames-dir /app/output_data/frames_480p \
  --sentences-per-chunk 10 \
  --chunk-overlap 4

# Stary sposÃ³b (segment-based chunking po 5 segmentÃ³w)
./run-preprocessor.sh generate-embeddings \
  --transcription-jsons /app/output_data/transcriptions \
  --frames-dir /app/output_data/frames_480p \
  --segment-chunking

# Text + video embeddings (rÄ™cznie)
./run-preprocessor.sh generate-embeddings \
  --transcription-jsons /app/output_data/transcriptions \
  --frames-dir /app/output_data/frames_480p \
  --batch-size 28 \
  --generate-text \
  --generate-video
```

**Zalety sentence-based chunking:**
- âœ… Lepszy kontekst semantyczny (dzieli po naturalnych granicach)
- âœ… Overlap chroni przed gubieniem kontekstu na granicach
- âœ… Normalizacja interpunkcji eliminuje artefakty transkrypcji
- âœ… ÅÄ…czenie krÃ³tkich fragmentÃ³w zapewnia minimalny kontekst

### generate-elastic-documents

Generowanie dokumentÃ³w Elasticsearch (Å‚Ä…czenie transkrypcji, embeddingÃ³w, scen, postaci).

```bash
./run-preprocessor.sh generate-elastic-documents \
  --transcription-jsons /app/output_data/transcriptions \
  --embeddings-dir /app/output_data/embeddings \
  --scene-timestamps-dir /app/output_data/scene_timestamps \
  --name ranczo \
  --output-dir /app/output_data/elastic_documents
```

### index

Indeksowanie w Elasticsearch (tworzy 4 indeksy: segments, text_embeddings, video_embeddings, episode_names).

```bash
# Nowy indeks
./run-preprocessor.sh index \
  --name ranczo \
  --elastic-documents-dir /app/output_data/elastic_documents

# Append do istniejÄ…cego
./run-preprocessor.sh index \
  --name ranczo \
  --elastic-documents-dir /app/output_data/elastic_documents \
  --append

# Dry run (walidacja bez wysyÅ‚ania do ES)
./run-preprocessor.sh index \
  --name ranczo \
  --elastic-documents-dir /app/output_data/elastic_documents \
  --dry-run
```

### search

Kompleksowe narzÄ™dzie do przeszukiwania zaindeksowanych danych w Elasticsearch.

**Tryby wyszukiwania:**
- Full-text search (BM25) - wyszukiwanie w transkrypcjach
- Semantic text search - wyszukiwanie po embedingach tekstowych (kNN + HNSW)
- Semantic image search - wyszukiwanie podobnych scen po obrazku (kNN + HNSW)
- Cross-modal search - wyszukiwanie video po zapytaniu tekstowym (kNN + HNSW)
- Character search - wyszukiwanie po wykrytych postaciach
- Episode name search - wyszukiwanie po nazwach odcinkÃ³w (fuzzy + semantic kNN)
- Perceptual hash - znajdowanie duplikatÃ³w/podobnych klatek

**Semantic search:**
Wszystkie semantic search wykorzystujÄ… **kNN query z HNSW index** zamiast brute-force `script_score`:
- âœ… **~10-100x szybsze** wyszukiwanie
- âœ… **Approximate nearest neighbors** (dokÅ‚adnoÅ›Ä‡ ~95%+)
- âœ… **Skalowalne** dla duÅ¼ych zbiorÃ³w danych
- âš ï¸ Trade-off: speed vs perfect accuracy (optymalne zamiast perfekcyjne)

```bash
# Statystyki i lista postaci
./run-preprocessor.sh search --stats
./run-preprocessor.sh search --list-characters

# Wyszukiwanie tekstowe
./run-preprocessor.sh search --text "Kto tu rzÄ…dzi" --limit 5

# Semantic search
./run-preprocessor.sh search --text-semantic "wesele" --season 10

# Image search (semantic)
./run-preprocessor.sh search --image /input_data/screenshot.jpg --character "Lucy"

# Cross-modal search (text â†’ video)
./run-preprocessor.sh search --text-to-video "Lucy w stodole" --limit 10

# Episode name search (fuzzy)
./run-preprocessor.sh search --episode-name "Spadek"
./run-preprocessor.sh search --episode-name "Wielkie wybory" --season 1

# Episode name search (semantic)
./run-preprocessor.sh search --episode-name-semantic "wesele"
./run-preprocessor.sh search --episode-name-semantic "Å›wiÄ™ta" --limit 10

# Perceptual hash (string lub Å›cieÅ¼ka do obrazka)
./run-preprocessor.sh search --hash "191b075b6d0363cf"
./run-preprocessor.sh search --hash /input_data/frame.jpg
```

**ğŸ“– PeÅ‚na dokumentacja:** [SEARCH_GUIDE.md](SEARCH_GUIDE.md)

---

## Scenariusze uÅ¼ycia

### 1. PeÅ‚ny pipeline od zera (11 krokÃ³w)

```bash
cd preprocessor
mkdir -p input_data/videos output_data
cp /Å›cieÅ¼ka/do/*.mp4 input_data/videos/

docker-compose build

./run-preprocessor.sh run-all /input_data/videos \
  --scrape-urls https://ranczo.fandom.com/wiki/Seria_I \
  --character-urls https://ranczo.fandom.com/wiki/Lista_postaci \
  --series-name ranczo
```

### 2. Z gotowÄ… transkrypcjÄ… i transkodowaniem

```bash
./run-preprocessor.sh detect-scenes /input_data/transcoded_videos

./run-preprocessor.sh export-frames /input_data/transcoded_videos \
  --episodes-info-json /input_data/episodes.json \
  --scene-timestamps-dir /app/output_data/scene_timestamps \
  --name ranczo

./run-preprocessor.sh image-hashing \
  --frames-dir /app/output_data/frames_480p \
  --episodes-info-json /input_data/episodes.json \
  --name ranczo

./run-preprocessor.sh generate-embeddings \
  --transcription-jsons /app/output_data/transcriptions \
  --frames-dir /app/output_data/frames_480p

./run-preprocessor.sh generate-elastic-documents \
  --transcription-jsons /app/output_data/transcriptions \
  --embeddings-dir /app/output_data/embeddings \
  --scene-timestamps-dir /app/output_data/scene_timestamps \
  --name ranczo

./run-preprocessor.sh index --name ranczo \
  --elastic-documents-dir /app/output_data/elastic_documents
```

### 3. Z gotowym episodes.json

```bash
./run-preprocessor.sh run-all /input_data/videos \
  --episodes-info-json /input_data/episodes.json \
  --series-name ranczo
```

### 4. PominiÄ™cie niektÃ³rych krokÃ³w (skip flags)

```bash
./run-preprocessor.sh run-all /input_data/videos \
  --episodes-info-json /input_data/episodes.json \
  --series-name ranczo \
  --skip-transcode \
  --skip-transcribe \
  --skip-frame-export \
  --skip-character-detection
```

### 5. Tylko transkrypcja (bez embeddings i wykrywania postaci)

```bash
./run-preprocessor.sh transcode /input_data/videos \
  --episodes-info-json /input_data/episodes.json

./run-preprocessor.sh transcribe /input_data/videos \
  --episodes-info-json /input_data/episodes.json \
  --name ranczo
```

---

## Technologie

| Komponent | Technologia | Opis |
|-----------|-------------|------|
| Transkodowanie | Jellyfin FFmpeg 7 + NVENC | GPU encoding h264_nvenc |
| Transkrypcja | Whisper large-v3-turbo | CTranslate2 GPU (~3GB) |
| Detekcja scen | TransNetV2 | PyTorch GPU (~1GB) |
| Eksport klatek | FFmpeg | 480p JPG extraction |
| Perceptual hashing | ImageHash | pHash algorithm |
| Embeddingi | Qwen3-VL-Embedding-2B | float16 (~5GB) |
| Face recognition | InsightFace (buffalo_l) | ArcFace embeddings (~1GB) |
| Object detection | D-FINE-X (obj2coco) | DETR-based, 59.3% AP (~0.5GB) |
| Image search | DuckDuckGo (DDGS) | Reference images download |
| LLM scraping | Qwen2.5-Coder-7B-Instruct | 8-bit, 128K context (~8GB) |
| Video decoding | Decord | GPU (5-10x szybsze niÅ¼ OpenCV) |
| Search | Elasticsearch | Full-text + vector indexing |
| Web scraping | crawl4ai | Markdown extraction |

**Cache modeli:** ~25-30GB w wolumenie `ranchbot-ai-models` (persistent)

**Modele pobierane automatycznie:**
- Whisper large-v3-turbo (~1.5GB)
- gme-Qwen2-VL-2B-Instruct (~5GB)
- D-FINE-X xlarge-obj2coco (~250MB)
- TransNetV2 (~200MB)
- InsightFace buffalo_l (~1GB)
- Qwen2.5-Coder-7B-Instruct (przez Ollama, ~8GB)
- Playwright Chromium (~300MB)

---

## Format plikÃ³w wideo

### Wspierane formaty

Pipeline wspiera wszystkie popularne formaty wideo (transkoder konwertuje wszystko do MP4):

**WejÅ›cie:** `.mp4`, `.avi`, `.mkv`, `.mov`, `.flv`, `.wmv`, `.webm`
**WyjÅ›cie:** `.mp4` (h264_nvenc, AAC audio)

### Nazewnictwo plikÃ³w

Pipeline ekstraktuje kod odcinka z nazwy pliku:

| Format | PrzykÅ‚ad | Uwagi |
|--------|----------|-------|
| `S01E01` | Ranczo S01E12.mp4 | Zalecane |
| `s01e12` | s01e12.mp4 | Case-insensitive |
| `E012` | E012.mp4 | Wymaga episodes.json |

**PrzykÅ‚ad transformacji:**
- Input: `Sezon 1/Ranczo S01E12.F012.Netflix.mkv`
- Output: `ranczo_S01E12.mp4`

Pliki bez rozpoznawalnego kodu bÄ™dÄ… pominiÄ™te.

---

## episodes.json

Automatycznie generowany przez LLM z wielu URLi naraz.

**Proces:**
1. Podajesz 1-10 URLi
2. crawl4ai pobiera wszystkie strony â†’ markdown
3. Qwen2.5-Coder-7B (128K context) â†’ JSON

**Format:**

```json
{
  "sources": [
    "https://ranczo.fandom.com/wiki/Seria_I",
    "https://filmweb.pl/serial/Ranczo-2006"
  ],
  "seasons": [
    {
      "season_number": 1,
      "episodes": [
        {
          "episode_number": 1,
          "title": "Pilot",
          "premiere_date": "2006-03-05",
          "viewership": 4500000
        }
      ]
    }
  ]
}
```

---

## characters.json

Automatycznie generowany przez LLM przy uÅ¼yciu `--character-urls`.

**Proces:**
1. Podajesz URLe z listami postaci
2. crawl4ai pobiera strony â†’ markdown
3. Qwen2.5-Coder-7B (128K context) â†’ JSON z imionami i nazwiskami
4. DuckDuckGo wyszukuje referencyjne zdjÄ™cia (automatycznie)
5. InsightFace weryfikuje twarze na zdjÄ™ciach (1 twarz = OK)

**Format:**

```json
{
  "sources": [
    "https://ranczo.fandom.com/wiki/Lista_postaci"
  ],
  "characters": [
    {
      "name": "Lucy Wilska",
      "role": "gÅ‚Ã³wna"
    },
    {
      "name": "Wicek Wilski",
      "role": "gÅ‚Ã³wna"
    }
  ]
}
```

**Referencyjne zdjÄ™cia:** Zapisywane w `output_data/characters/{nazwa_postaci}/00.jpg`, `01.jpg`, ...

---

## Instalacja

### Wymagania software

- Docker 20.10+
- Docker Compose 1.29+
- NVIDIA Container Toolkit (WYMAGANE)
- NVIDIA Driver 525+ (CUDA 12.1)
- Linux (Ubuntu 22.04) lub WSL2

### Instalacja NVIDIA Container Toolkit

```bash
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# Weryfikacja
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

---

## Monitoring

```bash
# Logi w czasie rzeczywistym
docker logs ranchbot-preprocessing-app -f

# WejÅ›cie do kontenera
docker-compose -f preprocessor/docker-compose.yml run --rm preprocessor bash

# Sprawdzenie GPU
nvidia-smi

# Sprawdzenie NVENC
ffmpeg -encoders | grep nvenc
```

---

## Changelog

### 2026-01-03 - Optymalizacje search i embeddings

**Search (kNN + HNSW):**
- âœ… Zamiana `script_score` na **kNN query** dla wszystkich semantic search
- âœ… ~10-100x szybsze wyszukiwanie (approximate nearest neighbors)
- âœ… HNSW index juÅ¼ byÅ‚ w mappingach, teraz faktycznie wykorzystywany

**Text embeddings (sentence-based chunking):**
- âœ… DomyÅ›lnie **8 zdaÅ„ + 3 overlap** (byÅ‚o: 5 segmentÃ³w bez overlapa)
- âœ… Normalizacja interpunkcji: `...` â†’ `.`, `!!!` â†’ `!`, `???` â†’ `?`
- âœ… ÅÄ…czenie krÃ³tkich fragmentÃ³w (min 30 znakÃ³w)
- âœ… PrzeÅ‚Ä…czniki CLI: `--sentence-chunking/--segment-chunking`
- âœ… Parametry: `--sentences-per-chunk`, `--chunk-overlap`
- âœ… Finalne chunki: ~240-480 znakÃ³w kontekstu

**Bugfixy:**
- âœ… Naprawiono bÅ‚Ä…d `LoggerNotFinalizedException` w frame sub-procesorach

---

## Troubleshooting

### Sprawdzenie GPU i NVENC

```bash
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
docker-compose -f preprocessor/docker-compose.yml run --rm preprocessor ffmpeg -encoders | grep nvenc
```

### Brak miejsca na dysku

```bash
cd preprocessor
docker system prune -a
docker volume prune

# Uwaga: re-download modeli przy nastÄ™pnym uruchomieniu (~30GB)
docker volume rm ranchbot-ai-models
```

### Out of memory (CUDA OOM)

```bash
# Aplikacja domyÅ›lnie uÅ¼ywa batch_size=28 (RTX 3090 24GB)
# JeÅ›li masz innÄ… kartÄ™, musisz dostosowaÄ‡ rÄ™cznie:
./run-preprocessor.sh generate-embeddings --batch-size 14  # dla ~16GB VRAM
./run-preprocessor.sh generate-embeddings --batch-size 7   # dla ~12GB VRAM

# Dla run-all: brak moÅ¼liwoÅ›ci ustawienia batch-size przez flagÄ™
# NaleÅ¼y edytowaÄ‡ config/config.py â†’ settings.embedding.batch_size
```

### Kontener siÄ™ crashuje

```bash
docker logs ranchbot-preprocessing-app --tail 200
docker-compose -f preprocessor/docker-compose.yml run --rm preprocessor bash
```

---

## WydajnoÅ›Ä‡ (RTX 3090 + 64GB RAM)

**Konfiguracja testowa (jedyna wspierana):**

| Metryka | WartoÅ›Ä‡                         |
|---------|---------------------------------|
| **GPU** | **RTX 3090 24GB**               |
| **RAM** | **64GB**                        |
| **Throughput** | **~3-4 odcinki/godzinÄ™**        |
| **Batch size** | **28 (default)**                |
| **Peak VRAM** | **~12GB (~50% wykorzystania)**  |
| **Peak RAM** | **~32GB (~50% wykorzystania)**  |
| **Przetwarzanie** | **Sekwencyjne (1 plik na raz)** |

Pipeline sekwencyjny (jeden plik na raz w kaÅ¼dej fazie) maksymalnie wykorzystuje GPU bez marnotrawstwa zasobÃ³w na rÃ³wnolegÅ‚oÅ›Ä‡.