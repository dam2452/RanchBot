version: '3.8'

services:
  preprocessor:
    build:
      context: ..
      dockerfile: preprocessor/Dockerfile
    image: ranczo-preprocessor:latest
    container_name: ranchbot-preprocessing-app

    runtime: nvidia

    env_file:
      - .env

    environment:
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - PULL_EXTRA_MODELS=true
      - DOCKER_CONTAINER=true
      - PYTHONUNBUFFERED=1
      - HF_HOME=/models/huggingface
      - TRANSFORMERS_CACHE=/models/huggingface
      - TORCH_HOME=/models/torch
      - WHISPER_CACHE=/models/whisper
      - OLLAMA_MODELS=/models/ollama

    volumes:
      - ./input_data:/input_data:ro
      - ./output_data:/app/output_data
      - ml_models:/models

    ports:
      - "11434:11434"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu, video, compute, utility]

# =============================================================================
# NAMED VOLUMES - Persist on the host filesystem!
# =============================================================================
# Location: /var/lib/docker/volumes/ranczo-ml-models
#
# To inspect: docker volume inspect ranczo-ml-models
# To backup:  docker run --rm -v ml_models:/data -v $(pwd):/backup alpine tar czf /backup/models.tar.gz /data
# To clear:   docker volume rm ranczo-ml-models
# =============================================================================
volumes:
  ml_models:
    name: ranchbot-ai-models
    driver: local
